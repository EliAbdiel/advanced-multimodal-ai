import base64
import chainlit as cl

from langchain_core.messages import HumanMessage
from langchain_core.output_parsers import StrOutputParser
from src.utils.llm_setup import get_gemini_llm

def prompt_func_audio(data: dict) -> list:
    """
    Creates a formatted message for the chat model using text and audio data.

    Formats the input data into a structure suitable for the chat model, 
    combining both text and audio components into a single message.

    Args:
    ----------
    data : dict
        A dictionary containing the keys "text" and "audio", where "text" 
        is the textual content and "audio" is a base64 encoded audio string.

    Returns:
    -------
    list
        A list containing a HumanMessage formatted with the combined text 
        and audio data.
    """
    text = data["text"]
    audio = data["audio"]

    audio_part = {
        "type": "media",
        "data": audio,
        "mime_type": "audio/mpeg",
    }

    content_parts = []
    text_part = {"type": "text", "text": text}
    content_parts.append(audio_part)
    content_parts.append(text_part)

    human_message = [HumanMessage(content=content_parts)]

    return human_message

async def process_audio(file: cl.File, user_message: str) -> str:
    """
    Processes an audio file and generates a response using the chat model.

    Reads the audio file, converts it to base64 encoding, and uses the chat model
    to analyze it along with the user's message. Notifies the user about the 
    processing status.

    Args:
    ----------
    file : cl.File
        The audio file to be processed
    user_message : str
        The user's message accompanying the audio file

    Returns:
    -------
    str
        The response generated by the chat model after analyzing the audio
    """
    await cl.Message(content=f"Processing your audio file **`{file.name}`**... Please hold on while I work on it!").send()

    audio_file_path = file.path

    with open(audio_file_path, "rb") as audio_file:
        encoded_audio = base64.b64encode(audio_file.read()).decode("utf-8")

    llm = await get_gemini_llm()

    chain = prompt_func_audio | llm | StrOutputParser()
    answer = await chain.ainvoke({"text": user_message, "audio": encoded_audio})

    # print("\nAudio Understand Metadata:")
    # print(answer_chain.usage_metadata)
        
    return answer