import base64
import chainlit as cl

from io import BytesIO
from PIL import Image
from langchain_core.messages import HumanMessage
from langchain_core.output_parsers import StrOutputParser
from src.utils.llm_setup import get_gemini_llm

def prompt_func_img(data: dict) -> list:
    """
    Creates a formatted message for the chat model using text and image data.

    Formats the input data into a structure suitable for the 
    chat model, combining both text and image components.

    Args:
    ----------
    data : dict
        A dictionary containing the keys "text" and "image", where "text" 
        is the textual content and "image" is a base64 encoded image string.

    Returns:
    -------
    list
        A list containing a HumanMessage formatted with the combined text 
        and image data.
    """
    text = data["text"]
    image = data["image"]

    image_part = {
        "type": "image_url",
        "image_url": f"data:image/jpeg;base64,{image}",
    }

    content_parts = []
    text_part = {"type": "text", "text": text}
    content_parts.append(image_part)
    content_parts.append(text_part)
    
    human_message = [HumanMessage(content=content_parts)]

    return human_message

async def process_img(file: cl.File, user_message: str) -> str:
    """
    Processes an image file and generates a description.

    Converts the image to a base64-encoded string and uses a chat model to describe it.
    Notifies the user about the task and sends the generated description.

    Args:
    ----------
    file : File
        The image file to be processed
    user_message : str
        The user's message accompanying the image file

    Returns:
    -------
    str
        A description of the image generated by the chat model.
    """
    await cl.Message(content=f"Processing your image file **`{file.name}`**... Please hold on while I work on it!").send()
    
    pil_image = Image.open(file.path)
    buffered = BytesIO()
    pil_image.save(buffered, format="JPEG")
    img_str_b64 = base64.b64encode(buffered.getvalue()).decode("utf-8")
    
    llm = await get_gemini_llm()

    chain = prompt_func_img | llm | StrOutputParser()
    answer = await chain.ainvoke({"text": user_message, "image": img_str_b64})

    # print("\nImage Understand Metadata:")
    # print(answer_chain.usage_metadata)
        
    return answer